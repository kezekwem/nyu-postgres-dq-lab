{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46a606ba",
   "metadata": {},
   "source": [
    "# Lab 06 ‚Äî Data Quality & Governance (DashDash) ‚Äî **All-Python + PostgreSQL** (Codespaces Ready)\n",
    "\n",
    "*Adapted from the dbt-based lab to run end-to-end in a single Jupyter Notebook using Python (SQLAlchemy, pandas) against PostgreSQL.*  \n",
    "**Course:** MASY1-GC 3260 ¬∑ Advanced Data Warehousing & Applications\n",
    "\n",
    "**How to use (students):**\n",
    "1. Fill in your PostgreSQL credentials in **Block02-Config** (or set `DATABASE_URL` in the Codespace).\n",
    "2. Run the notebook top-to-bottom.\n",
    "3. The notebook will: create/load CSVs ‚Üí seed into Postgres ‚Üí build staging **views** ‚Üí run DQ tests ‚Üí build marts ‚Üí compute KPIs ‚Üí write a stakeholder reply.\n",
    "4. All artifacts (CSVs, RUN_LOG.txt, sample exports) are saved under `outputs/`.\n",
    "\n",
    "**Instructor/Admin:** set `DB_MODE = \"admin\"` and run the safety cell; you can demo in `public` if you have CREATE on `public`.\n",
    "\n",
    "> **AI Disclosure:** This notebook template was generated with GPT-5 Pro on 2025-10-08 22:04 UTC. You are expected to understand and defend the code you submit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f384cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Block01-Setup | Cell01: Dependency installation & timers\n",
    "# ------------------------------\n",
    "\n",
    "import datetime, importlib, sys, subprocess, json, traceback\n",
    "from pathlib import Path\n",
    "\n",
    "# Initialize project-level tracking variables\n",
    "project_start_time = datetime.datetime.now()\n",
    "total_project_cells_executed = 0\n",
    "print(f\"üöÄ Project tracking initialized at {project_start_time:%Y-%m-%d %H:%M:%S}\")\n",
    "total_project_cells_executed += 1\n",
    "cell_core_logic_start_time = datetime.datetime.now()\n",
    "print(f\"üöÄ Starting Cell Logic... | Timestamp: {cell_core_logic_start_time:%H:%M:%S.%f}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --- Helper function to format time durations consistently ---\n",
    "def format_duration(delta):\n",
    "    \"\"\"Return duration as HH:MM:SS.mmm string from a timedelta or seconds.\"\"\"\n",
    "    if isinstance(delta, (int, float)):\n",
    "        total_ms = int(delta * 1000)\n",
    "    else:  # assume timedelta\n",
    "        total_ms = int(delta.total_seconds() * 1000)\n",
    "    hh, rem = divmod(total_ms, 3_600_000)\n",
    "    mm, rem = divmod(rem, 60_000)\n",
    "    ss, ms = divmod(rem, 1_000)\n",
    "    return f\"{hh:02d}:{mm:02d}:{ss:02d}.{ms:03d}\"\n",
    "\n",
    "# Optional rich printer\n",
    "try:\n",
    "    from rich import print as rprint\n",
    "    USE_RICH = True\n",
    "except ImportError:\n",
    "    USE_RICH = False\n",
    "    def rprint(msg, *args, **kwargs):  # fallback printer\n",
    "        print(msg)\n",
    "\n",
    "# Required packages\n",
    "PKGS = {\n",
    "    \"sqlalchemy\": [\"sqlalchemy\"],\n",
    "    \"psycopg2-binary\": [\"psycopg2\"],\n",
    "    \"pandas\": [\"pandas\"],\n",
    "    \"rich\": [\"rich\"],\n",
    "    \"python-dotenv\": [\"dotenv\"],\n",
    "    \"ipywidgets\": [\"ipywidgets\"],\n",
    "}\n",
    "\n",
    "def modules_ready(mods: list) -> bool:\n",
    "    for m in mods:\n",
    "        try:\n",
    "            importlib.import_module(m)\n",
    "        except ImportError:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def pip_install(pkg: str) -> bool:\n",
    "    rprint(f\"üîß Installing [bold]{pkg}[/bold]‚Ä¶\")\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", pkg])\n",
    "        rprint(f\"‚úÖ {pkg} installed.\\n\")\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as err:\n",
    "        rprint(f\"‚ùå Couldn‚Äôt install {pkg}: {err}\\n\")\n",
    "        return False\n",
    "    except Exception:\n",
    "        rprint(\"üö® Unexpected error:\\n\" + traceback.format_exc())\n",
    "        return False\n",
    "\n",
    "def run_dependency_check() -> bool:\n",
    "    t0 = datetime.datetime.now()\n",
    "    rprint(f\"üèÅ Dependency check started ‚Äî {t0:%H:%M:%S}\\n\")\n",
    "    missing = [pkg for pkg, mods in PKGS.items() if not modules_ready(mods)]\n",
    "    status_ok = True\n",
    "    if not missing:\n",
    "        rprint(\"üéâ All required packages are already present. No action needed!\")\n",
    "    else:\n",
    "        rprint(f\"üì¶ Missing packages detected: {json.dumps(missing)}\\n\")\n",
    "        failed = [p for p in missing if not pip_install(p)]\n",
    "        if \"rich\" in missing and \"rich\" not in failed and not USE_RICH:\n",
    "            importlib.invalidate_caches()\n",
    "            rich = importlib.import_module(\"rich\")\n",
    "            rprint = rich.print\n",
    "            globals()[\"rprint\"] = rprint\n",
    "        if failed:\n",
    "            rprint(\"‚ö†Ô∏è The following packages could NOT be installed automatically:\")\n",
    "            for p in failed: rprint(f\" ‚Ä¢ [bold red]{p}[/bold red]\")\n",
    "            rprint(\" ‚ûú Please install them manually.\\n\")\n",
    "            status_ok = False\n",
    "        else:\n",
    "            rprint(\"‚ú® All dependencies successfully installed!\")\n",
    "    duration_delta = datetime.datetime.now() - t0\n",
    "    rprint(f\"\\n‚è±Ô∏è Check finished in [bold]{format_duration(duration_delta)}[/bold] (HH:MM:SS.mmm)\\n\")\n",
    "    return status_ok\n",
    "\n",
    "dependencies_ready = run_dependency_check()\n",
    "\n",
    "# Imports\n",
    "if dependencies_ready:\n",
    "    print(\"‚úÖ Importing required libraries...\")\n",
    "    import time, os, re\n",
    "    import pandas as pd\n",
    "    from sqlalchemy import create_engine, text\n",
    "    from sqlalchemy import types as satypes\n",
    "    from dotenv import load_dotenv\n",
    "    import psycopg2\n",
    "    from IPython.display import display, Markdown, HTML\n",
    "    import ipywidgets as widgets\n",
    "    print(\"‚úÖ All libraries imported successfully.\")\n",
    "else:\n",
    "    print(\"‚ùå Critical libraries are missing. Cannot proceed with imports.\")\n",
    "\n",
    "# Create folders and simple archive helper\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "OUTPUTS_DIR = PROJECT_ROOT / \"outputs\"\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "OUTPUTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def archive_then_write(path: Path, data: bytes):\n",
    "    path = path.resolve()\n",
    "    if path.exists():\n",
    "        arch = path.parent / \"Archived\"\n",
    "        arch.mkdir(exist_ok=True)\n",
    "        ts = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        archived = arch / f\"{path.stem}__{ts}{path.suffix}\"\n",
    "        path.replace(archived)\n",
    "        print(f\"üî∂ Archived existing file to: {archived}\")\n",
    "    path.write_bytes(data)\n",
    "    print(f\"üìÑ Wrote file: {path}\")\n",
    "\n",
    "# Cell end timing\n",
    "print(\"-\" * 50)\n",
    "cell_core_logic_end_time = datetime.datetime.now()\n",
    "cell_execution_duration = cell_core_logic_end_time - cell_core_logic_start_time\n",
    "project_execution_duration = cell_core_logic_end_time - project_start_time\n",
    "formatted_cell_duration = format_duration(cell_execution_duration)\n",
    "formatted_project_duration = format_duration(project_execution_duration)\n",
    "print(f\"üèÅ Finished Cell Logic... | Timestamp: {cell_core_logic_end_time:%H:%M:%S.%f}\")\n",
    "if dependencies_ready:\n",
    "    print(\"‚úÖ All Tasks/Processes for this cell were completed successfully.\")\n",
    "else:\n",
    "    print(\"‚ùå Some critical tasks (dependency installation) failed. See logs above.\")\n",
    "print(f\"‚è±Ô∏è [Block01-Setup] Cell Execution Time: {formatted_cell_duration}\")\n",
    "print(f\"‚è≥ Total Project Execution Duration: {formatted_project_duration} | Cell: {total_project_cells_executed}\")\n",
    "# --- End Cell End Timing & Project Duration ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a1837a",
   "metadata": {},
   "source": [
    "### Block02 ‚Äî Config\n",
    "Configure PostgreSQL connection, set `search_path` safety, and create helpers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f535bcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Block02-Config | Cell01: DB config, engine, helpers\n",
    "# ------------------------------\n",
    "\n",
    "import datetime, os, re, traceback\n",
    "from contextlib import contextmanager\n",
    "\n",
    "# Continue timers\n",
    "try:\n",
    "    project_start_time\n",
    "except NameError:\n",
    "    project_start_time = datetime.datetime.now()\n",
    "try:\n",
    "    total_project_cells_executed\n",
    "except NameError:\n",
    "    total_project_cells_executed = 0\n",
    "total_project_cells_executed += 1\n",
    "cell_core_logic_start_time = datetime.datetime.now()\n",
    "print(f\"üöÄ Starting Cell Logic... | Timestamp: {cell_core_logic_start_time:%H:%M:%S.%f}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Rich printer\n",
    "try:\n",
    "    from rich import print as rprint\n",
    "except Exception:\n",
    "    def rprint(*a, **k): print(*a, **k)\n",
    "\n",
    "def format_duration(delta):\n",
    "    if isinstance(delta, (int, float)):\n",
    "        total_ms = int(delta * 1000)\n",
    "    else:\n",
    "        total_ms = int(delta.total_seconds() * 1000)\n",
    "    hh, rem = divmod(total_ms, 3_600_000)\n",
    "    mm, rem = divmod(rem, 60_000)\n",
    "    ss, ms = divmod(rem, 1_000)\n",
    "    return f\"{hh:02d}:{mm:02d}:{ss:02d}.{ms:03d}\"\n",
    "\n",
    "# ------------------------------\n",
    "# üîê Credentials (edit here OR set env DATABASE_URL)\n",
    "# ------------------------------\n",
    "DB_MODE = os.getenv(\"DB_MODE\", \"student\")  # \"student\" or \"admin\"\n",
    "PGHOST = os.getenv(\"PGHOST\", \"YOUR_HOST\")          # e.g., ep-xyz.us-east-2.aws.neon.tech\n",
    "PGPORT = int(os.getenv(\"PGPORT\", \"5432\"))\n",
    "PGDATABASE = os.getenv(\"PGDATABASE\", \"YOUR_DBNAME\")\n",
    "PGUSER = os.getenv(\"PGUSER\", \"YOUR_USERNAME\")      # Student: usually your NetID-based username\n",
    "PGPASSWORD = os.getenv(\"PGPASSWORD\", \"YOUR_PASSWORD\")\n",
    "PGSSL = os.getenv(\"PGSSL\", \"require\")              # require / prefer / disable\n",
    "\n",
    "# If DATABASE_URL is set, it takes precedence.\n",
    "DATABASE_URL = os.getenv(\"DATABASE_URL\")\n",
    "if not DATABASE_URL:\n",
    "    DATABASE_URL = f\"postgresql://{PGUSER}:{PGPASSWORD}@{PGHOST}:{PGPORT}/{PGDATABASE}?sslmode={PGSSL}\"\n",
    "\n",
    "def _mask_url(url: str) -> str:\n",
    "    return re.sub(r\"(postgresql:\\/\\/[^:]+:)([^@]+)(@)\", r\"\\1******\\3\", url)\n",
    "\n",
    "rprint(f\"üîó Using DB URL: [dim]{_mask_url(DATABASE_URL)}[/dim]\")\n",
    "\n",
    "# ------------------------------\n",
    "# Engine + connection helpers\n",
    "# ------------------------------\n",
    "from sqlalchemy import create_engine, text\n",
    "_engine = None\n",
    "\n",
    "def get_engine():\n",
    "    global _engine\n",
    "    if _engine is None:\n",
    "        _engine = create_engine(DATABASE_URL, echo=False, future=True, pool_pre_ping=True)\n",
    "    return _engine\n",
    "\n",
    "@contextmanager\n",
    "def db_connect():\n",
    "    eng = get_engine()\n",
    "    conn = eng.connect()\n",
    "    try:\n",
    "        yield conn\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "# Safety: force schema to $user, allow admin in public if they have privilege\n",
    "def set_search_path_safely():\n",
    "    safety_block = \"\"\"\n",
    "    SET search_path TO \"$user\", public;\n",
    "    DO $$\n",
    "    DECLARE\n",
    "      current_schema_name text := current_schema();\n",
    "      current_user_name   text := current_user;\n",
    "      is_instructor       boolean := has_schema_privilege(current_user, 'public', 'CREATE');\n",
    "    BEGIN\n",
    "      IF current_schema_name <> current_user_name\n",
    "         AND NOT (is_instructor AND current_schema_name = 'public') THEN\n",
    "        RAISE EXCEPTION\n",
    "          'You are in schema \"%\", not your personal schema \"%\". Run: SET search_path TO \"$user\", public;',\n",
    "          current_schema_name, current_user_name;\n",
    "      END IF;\n",
    "\n",
    "      IF is_instructor AND current_schema_name = 'public' THEN\n",
    "        RAISE NOTICE 'Instructor mode: running as \"%\" in schema \"public\".', current_user_name;\n",
    "      END IF;\n",
    "    END $$;\n",
    "    \"\"\"\n",
    "    with db_connect() as conn:\n",
    "        conn.execute(text(safety_block))\n",
    "        conn.commit()\n",
    "\n",
    "def ensure_schema_exists(schema_name: str):\n",
    "    with db_connect() as conn:\n",
    "        conn.execute(text(f'CREATE SCHEMA IF NOT EXISTS \"{schema_name}\";'))\n",
    "        conn.execute(text(f'GRANT USAGE, CREATE ON SCHEMA \"{schema_name}\" TO \"{schema_name}\";'))\n",
    "        conn.commit()\n",
    "\n",
    "# Smoke test\n",
    "ok = True\n",
    "try:\n",
    "    with db_connect() as conn:\n",
    "        val = conn.execute(text(\"SELECT current_date\")).scalar_one()\n",
    "        user, schema = conn.execute(text(\"SELECT current_user, current_schema\")).first()\n",
    "    rprint(f\"‚úÖ Connected! current_date=[bold]{val}[/bold], user=[bold]{user}[/bold], schema=[bold]{schema}[/bold]\")\n",
    "except Exception as e:\n",
    "    ok = False\n",
    "    rprint(f\"[red]‚ùå Connection failed[/red]\\n{traceback.format_exc()}\")\n",
    "\n",
    "try:\n",
    "    set_search_path_safely()\n",
    "    rprint(\"üõ°Ô∏è search_path safety check applied.\")\n",
    "except Exception as e:\n",
    "    ok = False\n",
    "    rprint(f\"[red]‚ùå search_path safety failed[/red] ‚Äî {e}\")\n",
    "\n",
    "print(\"-\"*50)\n",
    "cell_core_logic_end_time = datetime.datetime.now()\n",
    "cell_execution_duration = cell_core_logic_end_time - cell_core_logic_start_time\n",
    "project_execution_duration = cell_core_logic_end_time - project_start_time\n",
    "rprint(\n",
    "    f\"üèÅ Config Finished | {cell_core_logic_end_time:%H:%M:%S.%f} | \"\n",
    "    f\"Cell: [bold]{format_duration(cell_execution_duration)}[/bold] | \"\n",
    "    f\"Project: [bold]{format_duration(project_execution_duration)}[/bold] | \"\n",
    "    f\"Cells Run: [bold]{total_project_cells_executed}[/bold]\"\n",
    ")\n",
    "if ok:\n",
    "    rprint(\"[green]‚úÖ DB config ready.[/green]\")\n",
    "else:\n",
    "    rprint(\"[red]‚ö†Ô∏è Some DB tasks failed. Fix credentials or privileges and retry.[/red]\")\n",
    "# --- End Cell End Timing & Project Duration ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3479e122",
   "metadata": {},
   "source": [
    "### Block03 ‚Äî Data\n",
    "Copy the sample CSVs (with small defects) into `./data` or replace them with instructor-provided files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f08d7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Block03-Data | Cell01: Create/load CSVs (with defects)\n",
    "# ------------------------------\n",
    "\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "total_project_cells_executed += 1\n",
    "cell_core_logic_start_time = datetime.datetime.now()\n",
    "print(f\"üöÄ Starting Cell Logic... | Timestamp: {cell_core_logic_start_time:%H:%M:%S.%f}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "DATA_DIR = Path(\"data\"); DATA_DIR.mkdir(exist_ok=True)\n",
    "# If the CSVs already exist (e.g., instructor replaced with official files), we keep them.\n",
    "# Otherwise we drop in the sample ones bundled with this repo template.\n",
    "bundled = {\n",
    "    \"restaurants.csv\": '/mnt/data/nyu-lab06-python-postgres/data/restaurants.csv',\n",
    "    \"couriers.csv\": '/mnt/data/nyu-lab06-python-postgres/data/couriers.csv',\n",
    "    \"customers.csv\": '/mnt/data/nyu-lab06-python-postgres/data/customers.csv',\n",
    "    \"orders.csv\": '/mnt/data/nyu-lab06-python-postgres/data/orders.csv',\n",
    "}\n",
    "\n",
    "for fname, src in bundled.items():\n",
    "    dest = DATA_DIR / fname\n",
    "    if dest.exists():\n",
    "        print(f\"‚úÖ Using existing CSV (kept): {dest.resolve()}\")\n",
    "    else:\n",
    "        Path(src).replace(dest)\n",
    "        print(f\"üìÑ Copied sample CSV ‚Üí {dest.resolve()}\")\n",
    "\n",
    "# Quick peek\n",
    "for fname in [\"restaurants.csv\", \"couriers.csv\", \"customers.csv\", \"orders.csv\"]:\n",
    "    p = DATA_DIR / fname\n",
    "    try:\n",
    "        df = pd.read_csv(p)\n",
    "        print(f\"üìä {fname} shape={df.shape} | path={p.resolve()}\")\n",
    "        display(df.head(3))\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not preview {fname} ‚Äî {e}\")\n",
    "\n",
    "print(\"-\"*50)\n",
    "cell_core_logic_end_time = datetime.datetime.now()\n",
    "cell_execution_duration = cell_core_logic_end_time - cell_core_logic_start_time\n",
    "project_execution_duration = cell_core_logic_end_time - project_start_time\n",
    "print(f\"üèÅ Finished Cell Logic... | Timestamp: {cell_core_logic_end_time:%H:%M:%S.%f}\")\n",
    "print(f\"‚úÖ All Tasks/Processes for this cell were completed successfully.\")\n",
    "print(f\"‚è±Ô∏è [Block03-Data] Cell Execution Time: {format_duration(cell_execution_duration)}\")\n",
    "print(f\"‚è≥ Total Project Execution Duration: {format_duration(project_execution_duration)} | Cell: {total_project_cells_executed}\")\n",
    "# --- End Cell End Timing & Project Duration ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b0b89c",
   "metadata": {},
   "source": [
    "### Block04 ‚Äî Seed\n",
    "Load CSVs into PostgreSQL tables in your personal schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e1ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Block04-Seed | Cell01: Load CSVs into Postgres tables\n",
    "# ------------------------------\n",
    "\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import types as satypes\n",
    "from pathlib import Path\n",
    "\n",
    "total_project_cells_executed += 1\n",
    "cell_core_logic_start_time = datetime.datetime.now()\n",
    "print(f\"üöÄ Starting Cell Logic... | Timestamp: {cell_core_logic_start_time:%H:%M:%S.%f}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "tables = {\n",
    "    \"restaurants\": {\"path\": DATA_DIR/\"restaurants.csv\"},\n",
    "    \"couriers\": {\"path\": DATA_DIR/\"couriers.csv\"},\n",
    "    \"customers\": {\"path\": DATA_DIR/\"customers.csv\"},\n",
    "    \"orders\": {\"path\": DATA_DIR/\"orders.csv\"},\n",
    "}\n",
    "\n",
    "# Optional: Drop and recreate as clean tables\n",
    "ddl = [\n",
    "    \"DROP VIEW IF EXISTS stg_orders, stg_restaurants, stg_couriers, stg_customers CASCADE;\",\n",
    "    \"DROP VIEW IF EXISTS fct_deliveries, dim_restaurant, dim_courier, dim_customer, kpi_delivery_overview, monitoring_dq_exceptions CASCADE;\"\n",
    "]\n",
    "\n",
    "with db_connect() as conn:\n",
    "    for stmt in ddl:\n",
    "        try:\n",
    "            conn.execute(text(stmt))\n",
    "        except Exception:\n",
    "            pass\n",
    "    conn.commit()\n",
    "\n",
    "# Use pandas.to_sql for simplicity; types inferred reasonably\n",
    "# Note: We intentionally do not add PK/constraints here; tests operate at staging layer.\n",
    "for tname, info in tables.items():\n",
    "    df = pd.read_csv(info[\"path\"])\n",
    "    df.to_sql(tname, con=get_engine(), if_exists=\"replace\", index=False)\n",
    "    print(f\"üìÑ Loaded table: {tname} (rows={len(df)})\")\n",
    "\n",
    "# Verify\n",
    "with db_connect() as conn:\n",
    "    for tname in tables:\n",
    "        cnt = conn.execute(text(f\"SELECT COUNT(*) FROM {tname}\")).scalar_one()\n",
    "        print(f\"‚úÖ {tname}: {cnt} row(s)\")\n",
    "\n",
    "print(\"-\"*50)\n",
    "cell_core_logic_end_time = datetime.datetime.now()\n",
    "cell_execution_duration = cell_core_logic_end_time - cell_core_logic_start_time\n",
    "project_execution_duration = cell_core_logic_end_time - project_start_time\n",
    "print(f\"üèÅ Finished Cell Logic... | Timestamp: {cell_core_logic_end_time:%H:%M:%S.%f}\")\n",
    "print(f\"‚úÖ All Tasks/Processes for this cell were completed successfully.\")\n",
    "print(f\"‚è±Ô∏è [Block04-Seed] Cell Execution Time: {format_duration(cell_execution_duration)}\")\n",
    "print(f\"‚è≥ Total Project Execution Duration: {format_duration(project_execution_duration)} | Cell: {total_project_cells_executed}\")\n",
    "# --- End Cell End Timing & Project Duration ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853c5c23",
   "metadata": {},
   "source": [
    "### Block05 ‚Äî Staging\n",
    "Create staging **views** that normalize status, dedupe orders, and derive `delivery_minutes` + `on_time_flag`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de13fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Block05-Staging | Cell01: Create staging views\n",
    "# ------------------------------\n",
    "\n",
    "import datetime\n",
    "from sqlalchemy import text\n",
    "\n",
    "total_project_cells_executed += 1\n",
    "cell_core_logic_start_time = datetime.datetime.now()\n",
    "print(f\"üöÄ Starting Cell Logic... | Timestamp: {cell_core_logic_start_time:%H:%M:%S.%f}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "sql_stg_restaurants = \"\"\"\n",
    "CREATE OR REPLACE VIEW stg_restaurants AS\n",
    "SELECT * FROM restaurants;\n",
    "\"\"\"\n",
    "\n",
    "sql_stg_couriers = \"\"\"\n",
    "CREATE OR REPLACE VIEW stg_couriers AS\n",
    "SELECT\n",
    "  courier_id,\n",
    "  courier_name,\n",
    "  lower(vehicle_type) AS vehicle_type,\n",
    "  active_from, active_to, region\n",
    "FROM couriers;\n",
    "\"\"\"\n",
    "\n",
    "sql_stg_customers = \"\"\"\n",
    "CREATE OR REPLACE VIEW stg_customers AS\n",
    "SELECT * FROM customers;\n",
    "\"\"\"\n",
    "\n",
    "sql_stg_orders = \"\"\"\n",
    "CREATE OR REPLACE VIEW stg_orders AS\n",
    "WITH base AS (\n",
    "  SELECT\n",
    "    order_id,\n",
    "    customer_id,\n",
    "    restaurant_id,\n",
    "    courier_id,\n",
    "    NULLIF(order_timestamp,'')::timestamp    AS order_ts,\n",
    "    NULLIF(pickup_timestamp,'')::timestamp   AS pickup_ts,\n",
    "    NULLIF(dropoff_timestamp,'')::timestamp  AS dropoff_ts,\n",
    "    lower(trim(NULLIF(status,'')))           AS status_norm,\n",
    "    payment_method,\n",
    "    NULLIF(subtotal,'')::numeric(10,2)       AS subtotal,\n",
    "    NULLIF(delivery_fee,'')::numeric(10,2)   AS delivery_fee,\n",
    "    NULLIF(tip_amount,'')::numeric(10,2)     AS tip_amount,\n",
    "    NULLIF(distance_km,'')::numeric(6,2)     AS distance_km,\n",
    "    row_number() OVER (PARTITION BY order_id ORDER BY order_timestamp) AS rn\n",
    "  FROM orders\n",
    "),\n",
    "dedup AS (\n",
    "  SELECT * FROM base WHERE rn = 1\n",
    "),\n",
    "clean AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    CASE\n",
    "      WHEN status_norm IN ('delivered','canceled','returned') THEN status_norm\n",
    "      WHEN status_norm IS NULL THEN 'unknown'\n",
    "      ELSE 'unknown'\n",
    "    END AS status_final,\n",
    "    CASE\n",
    "      WHEN pickup_ts IS NOT NULL AND dropoff_ts IS NOT NULL\n",
    "        THEN EXTRACT(epoch FROM (dropoff_ts - pickup_ts))/60.0\n",
    "      ELSE NULL\n",
    "    END AS delivery_minutes\n",
    "  FROM dedup\n",
    ")\n",
    "SELECT\n",
    "  order_id, customer_id, restaurant_id, courier_id,\n",
    "  order_ts, pickup_ts, dropoff_ts,\n",
    "  status_final AS status,\n",
    "  payment_method, subtotal, delivery_fee, tip_amount, distance_km,\n",
    "  delivery_minutes,\n",
    "  CASE WHEN status_final = 'delivered' AND delivery_minutes <= 45 THEN TRUE ELSE FALSE END AS on_time_flag\n",
    "FROM clean;\n",
    "\"\"\"\n",
    "\n",
    "with db_connect() as conn:\n",
    "  for sql in [sql_stg_restaurants, sql_stg_couriers, sql_stg_customers, sql_stg_orders]:\n",
    "    conn.execute(text(sql))\n",
    "  conn.commit()\n",
    "\n",
    "print(\"‚úÖ Staging views created: stg_restaurants, stg_couriers, stg_customers, stg_orders\")\n",
    "\n",
    "print(\"-\"*50)\n",
    "cell_core_logic_end_time = datetime.datetime.now()\n",
    "cell_execution_duration = cell_core_logic_end_time - cell_core_logic_start_time\n",
    "project_execution_duration = cell_core_logic_end_time - project_start_time\n",
    "print(f\"üèÅ Finished Cell Logic... | Timestamp: {cell_core_logic_end_time:%H:%M:%S.%f}\")\n",
    "print(f\"‚úÖ All Tasks/Processes for this cell were completed successfully.\")\n",
    "print(f\"‚è±Ô∏è [Block05-Staging] Cell Execution Time: {format_duration(cell_execution_duration)}\")\n",
    "print(f\"‚è≥ Total Project Execution Duration: {format_duration(project_execution_duration)} | Cell: {total_project_cells_executed}\")\n",
    "# --- End Cell End Timing & Project Duration ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ede6d5d",
   "metadata": {},
   "source": [
    "### Block06 ‚Äî Tests (staging)\n",
    "Run core tests: not_null, unique, accepted_values, relationships, expression_is_true. Failures are stored in `dq_failures__*` tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3967fef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Block06-Tests | Cell01: Run DQ tests on staging\n",
    "# ------------------------------\n",
    "\n",
    "import datetime, json\n",
    "from sqlalchemy import text\n",
    "import pandas as pd\n",
    "\n",
    "total_project_cells_executed += 1\n",
    "cell_core_logic_start_time = datetime.datetime.now()\n",
    "print(f\"üöÄ Starting Cell Logic... | Timestamp: {cell_core_logic_start_time:%H:%M:%S.%f}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "OUTPUTS_DIR = Path(\"outputs\"); OUTPUTS_DIR.mkdir(exist_ok=True)\n",
    "RUN_LOG_PATH = OUTPUTS_DIR / \"RUN_LOG.txt\"\n",
    "\n",
    "# Define tests analogous to dbt's not_null, unique, accepted_values, relationships, expression_is_true\n",
    "TESTS = [\n",
    "  {\n",
    "    \"name\": \"stg_orders_order_id_not_null\",\n",
    "    \"severity\": \"error\",\n",
    "    \"sql\": \"SELECT * FROM stg_orders WHERE order_id IS NULL\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"stg_orders_order_id_unique\",\n",
    "    \"severity\": \"error\",\n",
    "    \"sql\": \"SELECT order_id, COUNT(*) AS cnt FROM stg_orders GROUP BY order_id HAVING COUNT(*) <> 1\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"stg_orders_status_accepted_values\",\n",
    "    \"severity\": \"warn\",\n",
    "    \"sql\": \"SELECT * FROM stg_orders WHERE status NOT IN ('delivered','canceled','returned','unknown') OR status IS NULL\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"stg_orders_restaurant_fk_relationships\",\n",
    "    \"severity\": \"error\",\n",
    "    \"sql\": \"SELECT o.* FROM stg_orders o LEFT JOIN stg_restaurants r ON o.restaurant_id=r.restaurant_id WHERE r.restaurant_id IS NULL\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"stg_orders_courier_fk_relationships\",\n",
    "    \"severity\": \"error\",\n",
    "    \"sql\": \"SELECT o.* FROM stg_orders o LEFT JOIN stg_couriers c ON o.courier_id=c.courier_id WHERE o.courier_id IS NOT NULL AND c.courier_id IS NULL\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"stg_orders_delivery_minutes_nonnegative\",\n",
    "    \"severity\": \"error\",\n",
    "    \"sql\": \"SELECT * FROM stg_orders WHERE NOT (delivery_minutes IS NULL OR delivery_minutes >= 0)\"\n",
    "  },\n",
    "]\n",
    "\n",
    "def run_test_store_failures(test: dict) -> dict:\n",
    "    with db_connect() as conn:\n",
    "        df = pd.read_sql(text(test[\"sql\"]), conn)\n",
    "    fail_table = f\"dq_failures__{test['name']}\"\n",
    "    with db_connect() as conn:\n",
    "        conn.execute(text(f'DROP TABLE IF EXISTS \"{fail_table}\"'))\n",
    "        conn.commit()\n",
    "        if not df.empty:\n",
    "            df.to_sql(fail_table, con=get_engine(), if_exists=\"replace\", index=False)\n",
    "    return {\"name\": test[\"name\"], \"severity\": test[\"severity\"], \"failures\": len(df), \"failure_table\": fail_table if not df.empty else None}\n",
    "\n",
    "results = []\n",
    "for t in TESTS:\n",
    "    r = run_test_store_failures(t)\n",
    "    results.append(r)\n",
    "    level = \"‚ùå\" if (r[\"severity\"]==\"error\" and r[\"failures\"]>0) else (\"üî∂\" if r[\"failures\"]>0 else \"‚úÖ\")\n",
    "    extra = f\" ‚Üí stored in {r['failure_table']}\" if r[\"failure_table\"] else \"\"\n",
    "    print(f\"{level} {r['name']}: {r['failures']} failing rows{extra}\")\n",
    "\n",
    "# Write/append a RUN_LOG.txt\n",
    "ts = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "with open(RUN_LOG_PATH, \"a\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"\\n[{ts}] STAGING TESTS\\n\")\n",
    "    for r in results:\n",
    "        f.write(json.dumps(r) + \"\\n\")\n",
    "\n",
    "# Display summary\n",
    "df_summary = pd.DataFrame(results)\n",
    "display(df_summary)\n",
    "\n",
    "print(\"-\"*50)\n",
    "cell_core_logic_end_time = datetime.datetime.now()\n",
    "cell_execution_duration = cell_core_logic_end_time - cell_core_logic_start_time\n",
    "project_execution_duration = cell_core_logic_end_time - project_start_time\n",
    "print(f\"üèÅ Finished Cell Logic... | Timestamp: {cell_core_logic_end_time:%H:%M:%S.%f}\")\n",
    "print(f\"‚è±Ô∏è [Block06-Tests] Cell Execution Time: {format_duration(cell_execution_duration)}\")\n",
    "print(f\"‚è≥ Total Project Execution Duration: {format_duration(project_execution_duration)} | Cell: {total_project_cells_executed}\")\n",
    "# --- End Cell End Timing & Project Duration ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bee31fd",
   "metadata": {},
   "source": [
    "### Block07 ‚Äî Marts\n",
    "Create `fct_deliveries` (valid delivered rows) and thin dims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d7075e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Block07-Marts | Cell01: Create fact and dims\n",
    "# ------------------------------\n",
    "\n",
    "import datetime\n",
    "from sqlalchemy import text\n",
    "\n",
    "total_project_cells_executed += 1\n",
    "cell_core_logic_start_time = datetime.datetime.now()\n",
    "print(f\"üöÄ Starting Cell Logic... | Timestamp: {cell_core_logic_start_time:%H:%M:%S.%f}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "sql_fct = \"\"\"\n",
    "CREATE OR REPLACE VIEW fct_deliveries AS\n",
    "SELECT *\n",
    "FROM stg_orders o\n",
    "WHERE o.status = 'delivered'\n",
    "  AND o.restaurant_id IN (SELECT restaurant_id FROM stg_restaurants)\n",
    "  AND (o.courier_id IS NULL OR o.courier_id IN (SELECT courier_id FROM stg_couriers));\n",
    "\"\"\"\n",
    "\n",
    "sql_dim_rest = \"\"\"CREATE OR REPLACE VIEW dim_restaurant AS SELECT * FROM stg_restaurants;\"\"\"\n",
    "sql_dim_cour = \"\"\"CREATE OR REPLACE VIEW dim_courier AS SELECT * FROM stg_couriers;\"\"\"\n",
    "sql_dim_cust = \"\"\"CREATE OR REPLACE VIEW dim_customer AS SELECT * FROM stg_customers;\"\"\"\n",
    "\n",
    "with db_connect() as conn:\n",
    "    for sql in [sql_fct, sql_dim_rest, sql_dim_cour, sql_dim_cust]:\n",
    "        conn.execute(text(sql))\n",
    "    conn.commit()\n",
    "\n",
    "print(\"‚úÖ Marts created: fct_deliveries, dim_restaurant, dim_courier, dim_customer\")\n",
    "\n",
    "print(\"-\"*50)\n",
    "cell_core_logic_end_time = datetime.datetime.now()\n",
    "cell_execution_duration = cell_core_logic_end_time - cell_core_logic_start_time\n",
    "project_execution_duration = cell_core_logic_end_time - project_start_time\n",
    "print(f\"üèÅ Finished Cell Logic... | Timestamp: {cell_core_logic_end_time:%H:%M:%S.%f}\")\n",
    "print(f\"‚úÖ All Tasks/Processes for this cell were completed successfully.\")\n",
    "print(f\"‚è±Ô∏è [Block07-Marts] Cell Execution Time: {format_duration(cell_execution_duration)}\")\n",
    "print(f\"‚è≥ Total Project Execution Duration: {format_duration(project_execution_duration)} | Cell: {total_project_cells_executed}\")\n",
    "# --- End Cell End Timing & Project Duration ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84255af0",
   "metadata": {},
   "source": [
    "### Block08 ‚Äî Tests (marts)\n",
    "Validate fact/dim constraints and accepted values on courier vehicle types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80f1a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Block08-Tests | Cell02: Run DQ tests on marts\n",
    "# ------------------------------\n",
    "\n",
    "import datetime, json\n",
    "from sqlalchemy import text\n",
    "import pandas as pd\n",
    "\n",
    "total_project_cells_executed += 1\n",
    "cell_core_logic_start_time = datetime.datetime.now()\n",
    "print(f\"üöÄ Starting Cell Logic... | Timestamp: {cell_core_logic_start_time:%H:%M:%S.%f}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "OUTPUTS_DIR = Path(\"outputs\"); OUTPUTS_DIR.mkdir(exist_ok=True)\n",
    "RUN_LOG_PATH = OUTPUTS_DIR / \"RUN_LOG.txt\"\n",
    "\n",
    "TESTS_MARTS = [\n",
    "  {\n",
    "    \"name\": \"fct_deliveries_order_id_not_null\",\n",
    "    \"severity\": \"error\",\n",
    "    \"sql\": \"SELECT * FROM fct_deliveries WHERE order_id IS NULL\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"fct_deliveries_order_id_unique\",\n",
    "    \"severity\": \"error\",\n",
    "    \"sql\": \"SELECT order_id, COUNT(*) AS cnt FROM fct_deliveries GROUP BY order_id HAVING COUNT(*) <> 1\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"fct_deliveries_restaurant_fk_dim\",\n",
    "    \"severity\": \"error\",\n",
    "    \"sql\": \"SELECT f.* FROM fct_deliveries f LEFT JOIN dim_restaurant d ON f.restaurant_id=d.restaurant_id WHERE d.restaurant_id IS NULL\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"fct_deliveries_courier_fk_dim\",\n",
    "    \"severity\": \"error\",\n",
    "    \"sql\": \"SELECT f.* FROM fct_deliveries f LEFT JOIN dim_courier d ON f.courier_id=d.courier_id WHERE f.courier_id IS NOT NULL AND d.courier_id IS NULL\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"dim_courier_vehicle_type_accepted_values\",\n",
    "    \"severity\": \"error\",\n",
    "    \"sql\": \"SELECT * FROM dim_courier WHERE vehicle_type NOT IN ('bike','scooter','car') OR vehicle_type IS NULL\"\n",
    "  },\n",
    "]\n",
    "\n",
    "def run_test_store_failures(test: dict) -> dict:\n",
    "    with db_connect() as conn:\n",
    "        df = pd.read_sql(text(test[\"sql\"]), conn)\n",
    "    fail_table = f\"dq_failures__{test['name']}\"\n",
    "    with db_connect() as conn:\n",
    "        conn.execute(text(f'DROP TABLE IF EXISTS \"{fail_table}\"'))\n",
    "        conn.commit()\n",
    "        if not df.empty:\n",
    "            df.to_sql(fail_table, con=get_engine(), if_exists=\"replace\", index=False)\n",
    "    return {\"name\": test[\"name\"], \"severity\": test[\"severity\"], \"failures\": len(df), \"failure_table\": fail_table if not df.empty else None}\n",
    "\n",
    "results = []\n",
    "for t in TESTS_MARTS:\n",
    "    r = run_test_store_failures(t)\n",
    "    results.append(r)\n",
    "    level = \"‚ùå\" if (r[\"severity\"]==\"error\" and r[\"failures\"]>0) else (\"üî∂\" if r[\"failures\"]>0 else \"‚úÖ\")\n",
    "    extra = f\" ‚Üí stored in {r['failure_table']}\" if r[\"failure_table\"] else \"\"\n",
    "    print(f\"{level} {r['name']}: {r['failures']} failing rows{extra}\")\n",
    "\n",
    "ts = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "with open(RUN_LOG_PATH, \"a\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"\\n[{ts}] MART TESTS\\n\")\n",
    "    for r in results:\n",
    "        f.write(json.dumps(r) + \"\\n\")\n",
    "\n",
    "df_summary = pd.DataFrame(results)\n",
    "display(df_summary)\n",
    "\n",
    "print(\"-\"*50)\n",
    "cell_core_logic_end_time = datetime.datetime.now()\n",
    "cell_execution_duration = cell_core_logic_end_time - cell_core_logic_start_time\n",
    "project_execution_duration = cell_core_logic_end_time - project_start_time\n",
    "print(f\"üèÅ Finished Cell Logic... | Timestamp: {cell_core_logic_end_time:%H:%M:%S.%f}\")\n",
    "print(f\"‚è±Ô∏è [Block08-Tests] Cell Execution Time: {format_duration(cell_execution_duration)}\")\n",
    "print(f\"‚è≥ Total Project Execution Duration: {format_duration(project_execution_duration)} | Cell: {total_project_cells_executed}\")\n",
    "# --- End Cell End Timing & Project Duration ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3614c29",
   "metadata": {},
   "source": [
    "### Block09 ‚Äî KPI\n",
    "Compute KPI view and preview values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5390b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Block09-KPI | Cell01: Compute KPI view and preview\n",
    "# ------------------------------\n",
    "\n",
    "import datetime, pandas as pd\n",
    "from sqlalchemy import text\n",
    "from pathlib import Path\n",
    "\n",
    "total_project_cells_executed += 1\n",
    "cell_core_logic_start_time = datetime.datetime.now()\n",
    "print(f\"üöÄ Starting Cell Logic... | Timestamp: {cell_core_logic_start_time:%H:%M:%S.%f}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "sql_kpi = \"\"\"\n",
    "CREATE OR REPLACE VIEW kpi_delivery_overview AS\n",
    "WITH d AS (SELECT * FROM fct_deliveries)\n",
    "SELECT\n",
    "  AVG(CASE WHEN on_time_flag THEN 1 ELSE 0 END)::numeric(5,4) AS on_time_rate,\n",
    "  AVG(delivery_minutes)::numeric(6,2)                         AS avg_delivery_minutes,\n",
    "  (\n",
    "    SELECT\n",
    "      (COUNT(*) FILTER (WHERE status IN ('canceled','returned'))::numeric\n",
    "       / NULLIF(COUNT(*),0))\n",
    "    FROM stg_orders\n",
    "  )::numeric(5,4) AS cancel_return_rate\n",
    ";\n",
    "\"\"\"\n",
    "\n",
    "with db_connect() as conn:\n",
    "    conn.execute(text(sql_kpi))\n",
    "    conn.commit()\n",
    "\n",
    "df = pd.read_sql(text(\"SELECT * FROM kpi_delivery_overview\"), get_engine())\n",
    "display(df)\n",
    "\n",
    "# Also print a 2-decimal summary\n",
    "if not df.empty:\n",
    "    on_time = float(df.loc[0,\"on_time_rate\"])*100 if df.loc[0,\"on_time_rate\"] is not None else 0.0\n",
    "    adm = float(df.loc[0,\"avg_delivery_minutes\"]) if df.loc[0,\"avg_delivery_minutes\"] is not None else 0.0\n",
    "    crr = float(df.loc[0,\"cancel_return_rate\"])*100 if df.loc[0,\"cancel_return_rate\"] is not None else 0.0\n",
    "    print(f\"üéØ On-Time Delivery %: {on_time:.2f}% | Avg Minutes: {adm:.2f} | Cancel/Return Rate: {crr:.2f}%\")\n",
    "\n",
    "print(\"-\"*50)\n",
    "cell_core_logic_end_time = datetime.datetime.now()\n",
    "cell_execution_duration = cell_core_logic_end_time - cell_core_logic_start_time\n",
    "project_execution_duration = cell_core_logic_end_time - project_start_time\n",
    "print(f\"üèÅ Finished Cell Logic... | Timestamp: {cell_core_logic_end_time:%H:%M:%S.%f}\")\n",
    "print(f\"‚úÖ All Tasks/Processes for this cell were completed successfully.\")\n",
    "print(f\"‚è±Ô∏è [Block09-KPI] Cell Execution Time: {format_duration(cell_execution_duration)}\")\n",
    "print(f\"‚è≥ Total Project Execution Duration: {format_duration(project_execution_duration)} | Cell: {total_project_cells_executed}\")\n",
    "# --- End Cell End Timing & Project Duration ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881ed14e",
   "metadata": {},
   "source": [
    "### Block10 ‚Äî Monitoring\n",
    "Create a `monitoring_dq_exceptions` view with excluded rows and reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a875ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Block10-Monitoring | Cell01: Create DQ Exceptions view\n",
    "# ------------------------------\n",
    "\n",
    "import datetime, pandas as pd\n",
    "from sqlalchemy import text\n",
    "\n",
    "total_project_cells_executed += 1\n",
    "cell_core_logic_start_time = datetime.datetime.now()\n",
    "print(f\"üöÄ Starting Cell Logic... | Timestamp: {cell_core_logic_start_time:%H:%M:%S.%f}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "sql_ex = \"\"\"\n",
    "CREATE OR REPLACE VIEW monitoring_dq_exceptions AS\n",
    "WITH base AS (\n",
    "  SELECT\n",
    "    order_id,\n",
    "    customer_id,\n",
    "    restaurant_id,\n",
    "    courier_id,\n",
    "    NULLIF(order_timestamp,'')::timestamp    AS order_ts,\n",
    "    NULLIF(pickup_timestamp,'')::timestamp   AS pickup_ts,\n",
    "    NULLIF(dropoff_timestamp,'')::timestamp  AS dropoff_ts,\n",
    "    lower(trim(NULLIF(status,'')))           AS status_norm,\n",
    "    row_number() OVER (PARTITION BY order_id ORDER BY order_timestamp) AS rn\n",
    "  FROM orders\n",
    "),\n",
    "dupes AS (\n",
    "  SELECT order_id, 'duplicate_order' AS reason FROM base WHERE rn > 1\n",
    "),\n",
    "bad_rest_fk AS (\n",
    "  SELECT o.order_id, 'bad_fk_restaurant' AS reason\n",
    "  FROM orders o\n",
    "  LEFT JOIN stg_restaurants r ON o.restaurant_id = r.restaurant_id\n",
    "  WHERE r.restaurant_id IS NULL\n",
    "),\n",
    "bad_cour_fk AS (\n",
    "  SELECT o.order_id, 'bad_fk_courier' AS reason\n",
    "  FROM orders o\n",
    "  LEFT JOIN stg_couriers c ON o.courier_id = c.courier_id\n",
    "  WHERE o.courier_id IS NOT NULL AND c.courier_id IS NULL\n",
    "),\n",
    "unknown_status AS (\n",
    "  SELECT order_id, 'status_unknown' AS reason\n",
    "  FROM base\n",
    "  WHERE status_norm IS NULL OR status_norm NOT IN ('delivered','canceled','returned')\n",
    ")\n",
    "SELECT DISTINCT order_id, reason\n",
    "FROM (\n",
    "  SELECT * FROM dupes\n",
    "  UNION ALL SELECT * FROM bad_rest_fk\n",
    "  UNION ALL SELECT * FROM bad_cour_fk\n",
    "  UNION ALL SELECT * FROM unknown_status\n",
    ") u\n",
    "ORDER BY order_id, reason;\n",
    "\"\"\"\n",
    "\n",
    "with db_connect() as conn:\n",
    "    conn.execute(text(sql_ex))\n",
    "    conn.commit()\n",
    "\n",
    "df = pd.read_sql(text(\"SELECT * FROM monitoring_dq_exceptions ORDER BY order_id, reason\"), get_engine())\n",
    "display(df)\n",
    "\n",
    "print(\"-\"*50)\n",
    "cell_core_logic_end_time = datetime.datetime.now()\n",
    "cell_execution_duration = cell_core_logic_end_time - cell_core_logic_start_time\n",
    "project_execution_duration = cell_core_logic_end_time - project_start_time\n",
    "print(f\"üèÅ Finished Cell Logic... | Timestamp: {cell_core_logic_end_time:%H:%M:%S.%f}\")\n",
    "print(f\"‚úÖ All Tasks/Processes for this cell were completed successfully.\")\n",
    "print(f\"‚è±Ô∏è [Block10-Monitoring] Cell Execution Time: {format_duration(cell_execution_duration)}\")\n",
    "print(f\"‚è≥ Total Project Execution Duration: {format_duration(project_execution_duration)} | Cell: {total_project_cells_executed}\")\n",
    "# --- End Cell End Timing & Project Duration ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fa1cb4",
   "metadata": {},
   "source": [
    "### Block11 ‚Äî Self‚ÄëSolve Test\n",
    "Singular test for dropoff/status logic; failing rows are written to `dq_failures__test_dropoff_status_logic`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52a2445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Block11-Tests | Cell03: Self-solve singular logic test\n",
    "# ------------------------------\n",
    "\n",
    "import datetime, json, pandas as pd\n",
    "from sqlalchemy import text\n",
    "\n",
    "total_project_cells_executed += 1\n",
    "cell_core_logic_start_time = datetime.datetime.now()\n",
    "print(f\"üöÄ Starting Cell Logic... | Timestamp: {cell_core_logic_start_time:%H:%M:%S.%f}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "OUTPUTS_DIR = Path(\"outputs\"); OUTPUTS_DIR.mkdir(exist_ok=True)\n",
    "RUN_LOG_PATH = OUTPUTS_DIR / \"RUN_LOG.txt\"\n",
    "\n",
    "sql_self = \"\"\"\n",
    "SELECT *\n",
    "FROM stg_orders\n",
    "WHERE (status IN ('canceled','returned') AND dropoff_ts IS NOT NULL)\n",
    "   OR (status = 'delivered' AND dropoff_ts IS NULL);\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(text(sql_self), get_engine())\n",
    "fail_table = \"dq_failures__test_dropoff_status_logic\"\n",
    "with db_connect() as conn:\n",
    "    conn.execute(text(f'DROP TABLE IF EXISTS \"{fail_table}\"'))\n",
    "    conn.commit()\n",
    "if not df.empty:\n",
    "    df.to_sql(fail_table, con=get_engine(), if_exists=\"replace\", index=False)\n",
    "\n",
    "print(f\"{'‚ùå' if not df.empty else '‚úÖ'} test_dropoff_status_logic: {len(df)} failing row(s){' ‚Üí stored in '+fail_table if not df.empty else ''}\")\n",
    "\n",
    "ts = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "with open(RUN_LOG_PATH, \"a\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"\\n[{ts}] SELF-SOLVE TEST\\n\")\n",
    "    f.write(json.dumps({{\"name\":\"test_dropoff_status_logic\",\"severity\":\"error\",\"failures\":len(df),\"failure_table\":(fail_table if not df.empty else None)}}) + \"\\n\")\n",
    "\n",
    "print(\"-\"*50)\n",
    "cell_core_logic_end_time = datetime.datetime.now()\n",
    "cell_execution_duration = cell_core_logic_end_time - cell_core_logic_start_time\n",
    "project_execution_duration = cell_core_logic_end_time - project_start_time\n",
    "print(f\"üèÅ Finished Cell Logic... | Timestamp: {cell_core_logic_end_time:%H:%M:%S.%f}\")\n",
    "print(f\"‚è±Ô∏è [Block11-Tests] Cell Execution Time: {format_duration(cell_execution_duration)}\")\n",
    "print(f\"‚è≥ Total Project Execution Duration: {format_duration(project_execution_duration)} | Cell: {total_project_cells_executed}\")\n",
    "# --- End Cell End Timing & Project Duration ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2287ebad",
   "metadata": {},
   "source": [
    "### Block12 ‚Äî Deliverable\n",
    "Write your stakeholder Markdown reply and export a few views to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb60e5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Block12-Deliverable | Cell01: Write stakeholder reply .md\n",
    "# ------------------------------\n",
    "\n",
    "import datetime, pandas as pd\n",
    "from sqlalchemy import text\n",
    "from pathlib import Path\n",
    "\n",
    "total_project_cells_executed += 1\n",
    "cell_core_logic_start_time = datetime.datetime.now()\n",
    "print(f\"üöÄ Starting Cell Logic... | Timestamp: {cell_core_logic_start_time:%H:%M:%S.%f}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Fetch KPI values\n",
    "df = pd.read_sql(text(\"SELECT * FROM kpi_delivery_overview\"), get_engine())\n",
    "on_time = adm = crr = 0.0\n",
    "if not df.empty:\n",
    "    on_time = float(df.loc[0,\"on_time_rate\"] or 0)*100.0\n",
    "    adm = float(df.loc[0,\"avg_delivery_minutes\"] or 0)\n",
    "    crr = float(df.loc[0,\"cancel_return_rate\"] or 0)*100.0\n",
    "\n",
    "# Student placeholders\n",
    "FIRST = os.getenv(\"STUDENT_FIRST\", \"First\")\n",
    "LAST = os.getenv(\"STUDENT_LAST\", \"Last\")\n",
    "NETID = os.getenv(\"STUDENT_NETID\", \"netid1234\")\n",
    "\n",
    "md = f\"\"\"Lab06_{FIRST}_{LAST}_{NETID}_Reply.md\n",
    "---\n",
    "# Stakeholder Reply ‚Äî DashDash Data Quality & KPIs\n",
    "\n",
    "**KPI summary:** On-Time Delivery: {on_time:.2f}% ¬∑ Average Delivery Minutes: {adm:.2f} ¬∑ Cancel/Return Rate: {crr:.2f}%\n",
    "\n",
    "**What changed after remediation**\n",
    "- Deduplicated orders by `order_id` (kept earliest record); removed duplicates from KPI universe.\n",
    "- Normalized mixed/invalid `status` values to {{delivered|canceled|returned|unknown}} to prevent leakage into dashboards.\n",
    "- Enforced referential integrity to restaurants/couriers; excluded rows with bad foreign keys from facts.\n",
    "- Added a DQ Exceptions view to track excluded rows and their reasons.\n",
    "\n",
    "**Recommendation**\n",
    "- Proceed with the ‚Äú10‚ÄëMinute Free Delivery Insurance‚Äù promo **if** daily on‚Äëtime % remains ‚â• 85% during soft‚Äëlaunch; otherwise, pause the offer in regions where scooter/car availability is thin.\n",
    "\n",
    "_Generated with GPT-5 Pro on {datetime.datetime.utcnow():%Y-%m-%d %H:%M UTC}. Student verified the numbers and process._\n",
    "\"\"\"\n",
    "\n",
    "OUTPUTS_DIR = Path(\"outputs\"); OUTPUTS_DIR.mkdir(exist_ok=True)\n",
    "outpath = OUTPUTS_DIR / f\"Lab06_{FIRST}_{LAST}_{NETID}_Reply.md\"\n",
    "outpath.write_text(\"\\n\".join(md.splitlines()[1:]), encoding=\"utf-8\")\n",
    "print(f\"üìÑ Wrote stakeholder reply: {outpath.resolve()}\")\n",
    "\n",
    "# Export a few useful views as CSVs for instructors\n",
    "exports = {\n",
    "    \"stg_orders\": OUTPUTS_DIR/\"stg_orders_export.csv\",\n",
    "    \"fct_deliveries\": OUTPUTS_DIR/\"fct_deliveries_export.csv\",\n",
    "    \"monitoring_dq_exceptions\": OUTPUTS_DIR/\"monitoring_dq_exceptions_export.csv\",\n",
    "    \"kpi_delivery_overview\": OUTPUTS_DIR/\"kpi_delivery_overview_export.csv\",\n",
    "}\n",
    "for view, path in exports.items():\n",
    "    try:\n",
    "        dfv = pd.read_sql(text(f\"SELECT * FROM {view}\"), get_engine())\n",
    "        dfv.to_csv(path, index=False)\n",
    "        print(f\"‚úÖ Exported {view} ‚Üí {path.resolve()} (rows={len(dfv)})\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not export {view}: {e}\")\n",
    "\n",
    "print(\"-\"*50)\n",
    "cell_core_logic_end_time = datetime.datetime.now()\n",
    "cell_execution_duration = cell_core_logic_end_time - cell_core_logic_start_time\n",
    "project_execution_duration = cell_core_logic_end_time - project_start_time\n",
    "print(f\"üèÅ Finished Cell Logic... | Timestamp: {cell_core_logic_end_time:%H:%M:%S.%f}\")\n",
    "print(f\"‚úÖ All Tasks/Processes for this cell were completed successfully.\")\n",
    "print(f\"‚è±Ô∏è [Block12-Deliverable] Cell Execution Time: {format_duration(cell_execution_duration)}\")\n",
    "print(f\"‚è≥ Total Project Execution Duration: {format_duration(project_execution_duration)} | Cell: {total_project_cells_executed}\")\n",
    "# --- End Cell End Timing & Project Duration ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1674f96f",
   "metadata": {},
   "source": [
    "### Block13 ‚Äî Finish\n",
    "Point to `outputs/RUN_LOG.txt`. You can download and submit this log as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf0078b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Block13-Finish | Cell01: Finish + show RUN_LOG path\n",
    "# ------------------------------\n",
    "\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "total_project_cells_executed += 1\n",
    "cell_core_logic_start_time = datetime.datetime.now()\n",
    "print(f\"üöÄ Starting Cell Logic... | Timestamp: {cell_core_logic_start_time:%H:%M:%S.%f}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "OUTPUTS_DIR = Path(\"outputs\"); OUTPUTS_DIR.mkdir(exist_ok=True)\n",
    "runlog = OUTPUTS_DIR / \"RUN_LOG.txt\"\n",
    "if not runlog.exists():\n",
    "    runlog.write_text(\"No tests run yet.\")\n",
    "\n",
    "print(f\"üìÑ Run log: {runlog.resolve()}\")\n",
    "\n",
    "print(\"-\"*50)\n",
    "cell_core_logic_end_time = datetime.datetime.now()\n",
    "cell_execution_duration = cell_core_logic_end_time - cell_core_logic_start_time\n",
    "project_execution_duration = cell_core_logic_end_time - project_start_time\n",
    "print(f\"üèÅ Finished Cell Logic... | Timestamp: {cell_core_logic_end_time:%H:%M:%S.%f}\")\n",
    "print(f\"‚úÖ All Tasks/Processes for this cell were completed successfully.\")\n",
    "print(f\"‚è±Ô∏è [Block13-Finish] Cell Execution Time: {format_duration(cell_execution_duration)}\")\n",
    "print(f\"‚è≥ Total Project Execution Duration: {format_duration(project_execution_duration)} | Cell: {total_project_cells_executed}\")\n",
    "# --- End Cell End Timing & Project Duration ---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
